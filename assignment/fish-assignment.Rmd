---
output: github_document
---

```{r include = FALSE}
knitr::opts_chunk$set(message = FALSE)
```
# Unit 3: Fisheries Collapse Module

This module will focus on understanding and replicating 
fisheries stock assessment data and fisheries collapse. 

Instead of working with independent dataframes, we will be working with a large
relational database which contains many different tables of different sizes and 
shapes, but that all all related to eachother through a series of different ids.


## The Database
We will use data from the [RAM Legacy Stock Assessment Database](https://doi.org/10.5281/zenodo.2542918)

First, load in the necessary libraries. Note that this time we need a package we 
haven't used before `readxl`. This package is useful for reading in .xls or 
.xlsx files. As always if you want more info on a package run `?readxl` after 
loading it.

```{r message = FALSE}
library("tidyverse")
library("readxl")
```

## Reading in the tables

First thing, you are going to need to download and unzip the files. Although you don't need 
to do this step more than once, Travis will need this code to be able to reproduce you work successfully,
unless you choose to push the datafiles up to git. 

```{r}
excel_version <- "RLSADB v4.44/DB Files With Assessment Data/RLSADB v4.44 (assessment data only).xlsx"
if(!file.exists(excel_version)){
  download.file("https://zenodo.org/record/2542919/files/RLSADB%20v4.44.zip?download=1",
                "ramlegacy.zip")
unzip("ramlegacy.zip") 
}
```

```{r}
sheets <- readxl::excel_sheets(excel_version) #use the readxl package to identify sheet names 
ram <- lapply(sheets, readxl::read_excel, path = excel_version)  #read the data from all 3 sheets into a list
names(ram) <- sheets # give the list of datatables their assigned sheet names

## check your names
names(ram)

## check your data
head(ram$area)

```

Side Note: You may notice the `lapply` function above. This function applies a given function
(in this case "read_excel") to all elements in a vector or list. This is the same 
as writing out read_excel for all the sheets contained in our file, or writing
a for loop `for(i in 1:length(sheets)){read_excel(sheets[i])}`. These are very powerful
functions we will learn more about later. For now, it's enough to recognize why we
have used it here. You can find more info in [Chapter 21 of the R4ds
book](http://r4ds.had.co.nz/iteration.html). 

# Exercise 1: Investigating the North-Atlantic Cod

Now we are ready to dive into our data.  First, We seek to replicate the following 
figure from the Millenium Ecosystem Assessment Project using the RAM data.


```{r}
tbl <-
ram$timeseries %>%
  left_join(ram$stock) %>%
  left_join(ram$area) %>%
  left_join(ram$tsmetrics, by = c("tsid" = "tsunique")) %>%
  filter(scientificname == "Gadus morhua",
         country == 'Canada' | country == 'USA') %>%
  filter(tsid == "TC-MT")

  #ram$tsmetrics %>% filter(tscategory == 'CATCH or LANDINGS') %>% count(tslong)

```

```{r}
landings_tbl <-
tbl %>%
  filter(tslong == 'Total catch (i.e. landings + discards. Add landings + discards to get this).')
landings_tbl


```


```{r}
grouped <- tbl %>% group_by(tsyear) %>% summarize(sum = sum(tsvalue, na.rm = TRUE))

ggplot(grouped, aes(x = tsyear, y= sum)) + geom_line(color='blue') + labs(title='Total Fish Landings in Tons', x='year', y='total')

grouped2 <- grouped %>%
  mutate(max=cummax(x=sum)) %>%
  mutate(collapsed = 10*max) %>%
  mutate(iscollapsed= collapsed>sum)



```



![](http://espm-157.carlboettiger.info/img/cod.jpg)

```{r}
ram$timeseries
```





**How does your graph compare to the one presented above?**

------


# Exercise 2: Group Assignment

## Stock Collapses

We seek to replicate the temporal trend in stock declines shown in [Worm et al 2006](http://doi.org/10.1126/science.1132294):

![](http://espm-157.carlboettiger.info/img/worm2006.jpg)





